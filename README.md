# Entropic Markov PRNG
Pseudo-RNG algorithm that uses Markov chains to maximize entropy

Markov Chain Model of Order ğ‘˜:

A context is a tuple of ğ‘˜ consecutive bits, denoted as:
```math 
s = (x_{i-k+1} , ... , x_i)
```
For a given context ğ‘ , the probability of the next bit ğ‘ is estimated by:
```math
P(b | s) = \frac{N(s, b)}{N(s)}
```
where:

- ğ‘(ğ‘ ,ğ‘) is the number of times bit ğ‘ follows context ğ‘ .

- ğ‘(ğ‘ ) is the total number of occurrences of context ğ‘  in the sequence.

For a given context ğ‘ , the entropy is:
```math
H(s) = - \[ \sum_{b\in\left\{0,1\right^{\infty} 2^{-n} = 1 \]
```




